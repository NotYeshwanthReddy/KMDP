{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the K1 Most Demanding products using K-means algorithm.\n",
    "The project has been clearly explained below along with \n",
    "- proper comments in the code, \n",
    "- Procedure, \n",
    "- Work done,\n",
    "- Results obtained,\n",
    "- Validaion and\n",
    "- Conclusion.\n",
    "<br>\n",
    "\n",
    "\n",
    "We would like consider the explanation below is clear and be used as a report of our work done.<br>\n",
    "Please have a look at the git repo for the dataset.<br>\n",
    "Github repo-<br>\n",
    "<a href='https://github.com/Yeshwanth-Reddyy/KMDP'>https://github.com/Yeshwanth-Reddyy/KMDP</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "text",
    "id": "0F6HPus74epQ"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on \t: 12/10/19\n",
    "Developer \t: Yeshwanth Reddy\n",
    "File Type\t: Python\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import heapq\n",
    "import random\n",
    "import datetime\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MeanShift\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Lf407M54epu"
   },
   "source": [
    "# Introduction and Data Pre-Processing\n",
    "Before Starting the project, we have the car dataset with all the \"'d' no. of features of each car\". Now, we need to generate the customers data based on these features.<br>\n",
    "Along with all the feature details, we also know the class of a car (unacc, acc, good, vgood). So, we can use this data to create satisfaction bit stings for each car assuming we have 500 customers.<br>\n",
    "I have used a random function and have chosen if a customer is satisfied by a product or not. If the car is of class vgood, then the random function gives 1 as output for 90% of times.<br>\n",
    "vgood - 90%<br>\n",
    "good - 75%<br>\n",
    "acc - 50%<br>\n",
    "unacc - 10%<br>\n",
    "\n",
    "Using this technique, I have constructed a SBS table of dimensions 1728x575. The rows are the products and columns are the customers. It has been saved to a SBS.csv file in data_process folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "Q8Qa5HlX4epx",
    "outputId": "7062aec9-08f2-4e57-de3d-52c5a019f05c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "Formatting data...\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Our Data format:                       \"\"\"\n",
    "#    buyingCost   v-high, high, med, low\n",
    "#    maintCost    v-high, high, med, low\n",
    "#    doors        2, 3, 4, 5-more\n",
    "#    seats        2, 4, more\n",
    "#    lug_boot     small, med, big\n",
    "#    safety       low, med, high\n",
    "\n",
    "# Create data file and creates a npArray \"data\" (uint8 format).\n",
    "def create_Data(fileLocation = \"./dataset/car/car.data\"):\n",
    "\tprint(\"Reading data...\")\n",
    "\tdata = pd.read_csv(fileLocation, header=None)\n",
    "\tdata = np.array(data)\n",
    "\tprint(\"Formatting data...\")\n",
    "\tdata[data=='5more'] = 5\n",
    "\tdata[data=='vhigh'] = 3\n",
    "\tdata[data=='more'] = 5\n",
    "\tdata[data=='high'] = 2\n",
    "\tdata[data=='big'] = 2\n",
    "\tdata[data=='med'] = 1\n",
    "\tdata[data=='low'] = 0\n",
    "\tdata[data=='small'] = 0\n",
    "\t# Classes defining if a user BUYs or NOT.\n",
    "\tdata[data=='unacc'] = 0\n",
    "\tdata[data=='acc'] = 1\n",
    "\tdata[data=='good'] = 2\n",
    "\tdata[data=='vgood'] = 3\n",
    "\tdata = np.array(data, dtype=np.uint8)\n",
    "\tnp.random.shuffle(data)\n",
    "\t\n",
    "\tfileName = fileLocation.split(\"/\")[-1].split(\".\")[0]\n",
    "\tpd.DataFrame(data, dtype=np.uint8).to_csv(\"./data_process/\"+fileName+\".csv\", header=None, index=None)\n",
    "\treturn data\n",
    "\n",
    "# Creates and saves a \"Satisfaction Bit String table\" from the \"data\" for 500 customers.\n",
    "def create_SBS(fileLocation=\"./dataset/car/car.data\", data = create_Data()):\n",
    "\tno_cust = 500\n",
    "\tprint(\"creating Empty SBS table...\")\n",
    "\tSBS = np.zeros((data.shape[0], no_cust), dtype=np.uint8)\n",
    "\t\n",
    "\tprint(\"Filling SBS table...\")\n",
    "\tfor i in range(SBS.shape[0]):\n",
    "\t\tfor j in range(SBS.shape[1]):\n",
    "\t\t\tif data[i][-1] == 3: \t# 90% chance\n",
    "\t\t\t\tSBS[i][j]= 0 if random.randint(0,100)%10==0 else 1\n",
    "\t\t\telif data[i][-1] == 2:  # 75% chance\n",
    "\t\t\t\tSBS[i][j]= 0 if random.randint(0,100)%4==0 else 1\n",
    "\t\t\telif data[i][-1] == 1:  # 50% chance\n",
    "\t\t\t\tSBS[i][j]= 0 if random.randint(0,100)%2==0 else 1\n",
    "\t\t\telif data[i][-1] == 0:  # 10% chance\n",
    "\t\t\t\tSBS[i][j]= 1 if random.randint(0,100)%10==0 else 0\n",
    "\t\n",
    "\tprint(\"Saving to file...\")\n",
    "\tfileName = fileLocation.split(\"/\")[-1].split(\".\")[0]\n",
    "\tpd.DataFrame(SBS, dtype=np.uint8).to_csv(\"./data_process/\"+fileName+\"_SBS.csv\", header=None, index=None)\n",
    "\treturn SBS\n",
    "\n",
    "\n",
    "# Reads data file and creates a npArray \"data\" (uint8 format).\n",
    "def read_Data(fileLocation='./data_process/car.csv'):\n",
    "\tprint(\"Reading data...\")\n",
    "\tdata = pd.read_csv(fileLocation, header=None)\n",
    "\tdata = np.array(data, dtype=np.uint8)\n",
    "\treturn data\n",
    "\n",
    "# Reads the saved Satisfaction Bit String from saved file.\n",
    "def read_SBS(SBSLocation='./data_process/car_SBS.csv'):\n",
    "\tprint(\"Reading SBS...\")\n",
    "\tSBS = pd.read_csv(SBSLocation, header=None)\n",
    "\tSBS = np.array(SBS, dtype=np.uint8)\n",
    "\treturn SBS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JNlJmU8Z4ep-"
   },
   "source": [
    "# K1MostDemandingProducts\n",
    "There are 2 things.\n",
    "- Predicting the satisfaction bit string(SBS) of a candidate product. <small>(done in pre-processing step)</small>.\n",
    "- Predicting the k-most demanding products based on the SBS.\n",
    "\n",
    "**Formulas Used:**-<br>\n",
    "$C$ = {$c_0, c_1, c_2,....c_nc$}  -- Customers<br>\n",
    "$EP$ = {$ep_0, ep_1, ep_2,....ep_nep$}  -- Existing products<br>\n",
    "$CP$ = {$cp_0, cp_1, cp_2,....cp_ncp$}  -- Candidate products<br>\n",
    "$kCP$ = {$kCP_1, kCP_2, kCP_3,....kCP_n$}  --  Set of Clusters<br>\n",
    "$kCP_1$ = {$cp_0, cp_3, cp_5,....cp_9$}  --  Cluster of candidate products<br><br>\n",
    "\n",
    "**(Counts no. of products a customer $c$ likes in the set of candidate products $CP$)**<br>\n",
    "$N$($CP, c$) = return No. of products $c$ likes in set $CP$. <br><br>\n",
    "**(Calculating the probability of a customer $c_j$ buying a candidate product $cp_i$)**<br>\n",
    "$p$($cp_i, c_j$) = $\\frac{1}{N(EP, c)+N(CP, c)}$ ------ if $c_j$ likes $cp_i$. <br>\n",
    "$p$($cp_i, c_j$) = 0  -------------------------------------  otherwise<br><br>\n",
    "**(Estimating the total buying probability of each product)**<br>\n",
    "E($kCP, C$) = $\\sum_{i=1}^{kcp} \\sum_{j=1}^{C} p(cp_i, c_j)$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ewc5gdE94eqC"
   },
   "outputs": [],
   "source": [
    "def N_Calc(SBS, EP, CP):\n",
    "\tcols = len(SBS[0])\n",
    "\tNsbs = [[0]*2]*cols\n",
    "\tfor i in range(cols):\n",
    "\t\tEP_count=0\n",
    "\t\tCP_count=0\n",
    "\t\tfor j in EP:\n",
    "\t\t\tif SBS[j][i]==1:\n",
    "\t\t\t\tEP_count+=1\n",
    "\t\tfor j in CP:\n",
    "\t\t\tif SBS[j][i]==1:\n",
    "\t\t\t\tCP_count+=1\n",
    "\t\tNsbs[i][0] = EP_count\n",
    "\t\tNsbs[i][1] = CP_count\n",
    "\treturn Nsbs\n",
    "\n",
    "def N(cust, Nsbs):\n",
    "\tEP_count = Nsbs[cust][0]\n",
    "\tCP_count = Nsbs[cust][1]\n",
    "\treturn EP_count+CP_count\n",
    "\n",
    "def P(cp_i, c_j, Nsbs, SBS):\n",
    "\tif SBS[cp_i][c_j]==1:\n",
    "\t\tp = 1 / N(c_j, Nsbs)\n",
    "\telse:\n",
    "\t\tp = 0\n",
    "\treturn p\n",
    "\n",
    "def E(kCP_n, C, Nsbs, SBS):\n",
    "\tE = 0\n",
    "\tfor cp_i in kCP_n:\n",
    "\t\tfor c_j in C:\n",
    "\t\t\tE += P(cp_i, c_j, Nsbs, SBS)\n",
    "\treturn E\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r9WBiwHy4eqR"
   },
   "source": [
    "## Single product based Greedy algorithm\n",
    "\n",
    "Let S denote a set containing a single candidate product cp in CP. <br>\n",
    "The SPG algorithm uses E(S, C), which computes the expected number of the customers in C for S, as the ranking function of the candidate products. <br><br>\n",
    "S = {$cp_0$}<br>\n",
    "$p$($S, c_j$) = $\\frac{1}{N(EP, c_j)+N(CP, c_j)}$ -- if $c_j$ likes S<br>\n",
    "$p$($S, c_j$) = 0  -- otherwise<br><br>\n",
    "E($S, C$) = $\\sum_{j=1}^{C} p(S, c_j)$ \n",
    "\n",
    "The candidate products with the top-k values of the ranking function are selected to form an approximate solution of the k-MDP discovering problem.<br>\n",
    "Algorithm 1: The SPG Algorithm <br>\n",
    "Input: N_vector(EP,C), set C of customer requirements, set CP\n",
    "of candidate product, and the value k <br>\n",
    "Output: A set of k candidate product\n",
    "``` python\n",
    "def SPGA(k):\n",
    "    for each candidate product cp in CP:\n",
    "        \"\"\"This is not needed as we already have it in our dataset.\"\"\"\n",
    "#         Compute the satisfaction bit string of cp;\n",
    "        S={cp};\n",
    "        Compute E(S,C);\n",
    "        if i<=k\n",
    "            Insert E(S,C) into the top-k list\n",
    "        elif E(S,C)> the smallest value in top-k list\n",
    "            Replace the smallest in top-k list with E(S,C);\n",
    "        Put the corresponding candidate products in the top-k list to set the kCP;\n",
    "    return kCP;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xDdz0u4m4eqU"
   },
   "outputs": [],
   "source": [
    "def SPG(k, SBS, EP, CP):\n",
    "\tk = [(0, 0)]*k\n",
    "\theapq.heapify(k)\n",
    "\tNsbs = N_Calc(SBS, EP, CP)\n",
    "\tfor cp in CP:\n",
    "\t\tS = set()\n",
    "\t\tS.add(cp)\n",
    "\t\te = E(S, C, Nsbs, SBS)\n",
    "\t\theapq.heappush(k, (e, cp))\n",
    "\t\theapq.heappop(k)\n",
    "\treturn k\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "md0nksdR4eqf"
   },
   "source": [
    "## Incremental Based Greedy Algorithm\n",
    "\n",
    "Let S denotes an empty set initially. <br>\n",
    "In each iteration, the IG algorithm selects one of the unselected candidate products cp, which has the maximum E(S $\\bigcup$ {cp}, C) value. <br>\n",
    "After inserting the selected candidate product into S, the values of the selection function for the unselected candidate products are recomputed in the following iteration to decide the next selected candidate product. <br>\n",
    "The above process continues until k candidate products have been selected.<br>\n",
    "\n",
    "Algorithm 2: The IG algorithm <br>\n",
    "Input: N_vector(EP,C), set C of customer requirements, set CP of candidate product, and the value k <br>\n",
    "Output: A set of k candidate product<br>\n",
    "\n",
    "```python\n",
    "def IG(k):\n",
    "    \"\"\"This is not needed as we already have the SBS in our dataset.\"\"\"\n",
    "#     for each candidate product cp in CP\n",
    "#         Compute the satisfaction bit string of cp;\n",
    "    S= null;\n",
    "    while (|S| < k):\n",
    "        max_E=0\n",
    "        max_P=0\n",
    "        for each candidate product cp in CP:\n",
    "            temp_S = S U {cp};\n",
    "            Compute E(temp_S,C);\n",
    "            if ( E(temp_S,C) > max_E ):\n",
    "                max_P={cp};\n",
    "                max_E= E(temp_S,C)\n",
    "        S=S U max_P;\n",
    "        CP=CP – max_P; \n",
    "\n",
    "    return kCP;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9D5rVLTH4eqj"
   },
   "outputs": [],
   "source": [
    "def IG(k, SBS, EP, CP):\n",
    "\tS = np.array((),dtype=np.uint8)\n",
    "\tNsbs = N_Calc(SBS, EP, CP)\n",
    "\twhile(len(S) < k):\n",
    "\t\tmax_E=0\n",
    "\t\tmax_P=0\n",
    "\t\tfor cp in CP:\n",
    "\t\t\ttemp_S = np.append(S, cp)\n",
    "\t\t\te = E(temp_S, C, Nsbs, SBS)\n",
    "\t\t\tif (e > max_E):\n",
    "\t\t\t\tmax_E = e\n",
    "\t\t\t\tmax_P = cp\n",
    "\t\tS = np.append(S, max_P)\n",
    "\t\tindex = np.argwhere(CP==max_P)\n",
    "\t\tCP = np.delete(CP, index)\n",
    "\treturn S\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hdA2lo6l3IXm"
   },
   "source": [
    "## Upper Bound Pruning Algorithm\n",
    "\n",
    "Not Written yet.<br>\n",
    "\n",
    "Algorithm 3: The UBP algorithm <br>\n",
    "Input: k, SBS, EP, CP <br>\n",
    "Output: A set of k candidate product<br>\n",
    "\n",
    "```python\n",
    "def UBP(k, SBS, EP, CP):\n",
    "    return kCP;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sEqVsjal3XKU"
   },
   "outputs": [],
   "source": [
    "def UBP(k, SBS, EP, CP):\n",
    "  return k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "94dRliaq4eq7"
   },
   "source": [
    "# Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking K1 as 5\n",
    "k=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "XRENtqbH5tqp",
    "outputId": "a55ed5e2-99d2-4043-e897-97cbea963062"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "Formatting data...\n",
      "creating Empty SBS table...\n",
      "Filling SBS table...\n",
      "Saving to file...\n"
     ]
    }
   ],
   "source": [
    "# Change the fileLocation to your car.data folder.\n",
    "read_data_location = \"./data_process/car.csv\"\n",
    "read_SBS_location = \"./data_process/car_SBS.csv\"\n",
    "dataset_location = \"./dataset/car/car.data\"\n",
    "\n",
    "# Creating the Satisfaction Bit String of every customer\n",
    "try:\n",
    "\tdata = read_Data(read_data_location) \n",
    "\tSBS = read_SBS(read_SBS_location)\n",
    "except:\n",
    "\tdata = create_Data(dataset_location) \n",
    "\tSBS = create_SBS(dataset_location, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "2MZknWKU4eq_",
    "outputId": "136f9274-da25-42dc-9777-1956e73b4d13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Product Based Greedy Algorithm : \n",
      " [(1.031818181818188, 601), (1.0409090909090968, 378), (1.0340909090909152, 1195), (1.0454545454545512, 1051), (1.0477272727272784, 540)]\n",
      "Time taken: 4\n",
      "Incremental Based Greedy Algorithm : \n",
      " [ 540 1051  378 1195  457]\n",
      "Time taken: 36\n"
     ]
    }
   ],
   "source": [
    "rows=len(SBS)\n",
    "cols=len(SBS[0])\n",
    "\n",
    "# Creating Sets of Customers, Candidate Products and Existing Products.\n",
    "C = np.arange(0, cols)\n",
    "CP = np.arange(0, (rows*70)//100)\n",
    "EP = np.arange((rows*70)//100, rows)\n",
    "# kCP = ?\n",
    "\n",
    "# SPGA\n",
    "timeTaken = datetime.datetime.now()\n",
    "SPG_k = SPG(k, SBS, EP, CP)\n",
    "timeTaken = datetime.datetime.now() - timeTaken \n",
    "print(\"Single Product Based Greedy Algorithm : \\n\", SPG_k)\n",
    "print(\"Time taken:\", timeTaken.seconds)\n",
    "\n",
    "# IG\n",
    "timeTaken = datetime.datetime.now()\n",
    "IG_k = IG(k, SBS, EP, CP)\n",
    "timeTaken = datetime.datetime.now() - timeTaken\n",
    "print(\"Incremental Based Greedy Algorithm : \\n\", IG_k)\n",
    "print(\"Time taken:\", timeTaken.seconds)\n",
    "\n",
    "# # UBP\n",
    "# timeTaken = datetime.datetime.now()\n",
    "# UBP_k = UBP(k, SBS, EP, CP)\n",
    "# timeTaken = datetime.datetime.now() - timeTaken\n",
    "# print(\"Upper Bound Pruning Algorithm : \\n\", UBP_k)\n",
    "# print(\"Time taken:\", timeTaken.seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e30tuStM-QGO"
   },
   "source": [
    "## K-Means\n",
    "Plotting the square error values for each no. of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "q6jV5lgU4erI",
    "outputId": "bea9eee1-5021-4f81-aacb-abbb92ca7bec"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEGCAYAAACpXNjrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3de5hddX3v8fdn9tySzORGkgkSMIgpLXoAIaUoXlAqNz2iR2rhUYnKET2KraU3rOeo1dpWrfIUsbZYUgK1XKRV0KIQ0WprRQ3IVUEiioQHkpCETC6Tuez5nj/Wb0/WDHPZyezLzN6f1/OsZ6/1W7+193f2DHzzu6zfUkRgZmZWSS31DsDMzBqPk4uZmVWck4uZmVWck4uZmVWck4uZmVVca70DmCmWLFkSK1eurHcYZmazyl133fV0RCwdW+7kkqxcuZINGzbUOwwzs1lF0mPjlbtbzMzMKs7JxczMKs7JxczMKs7JxczMKs7JxczMKs7JxczMKs5Tkaehd98gjz29l829+1g2v4NjVyysd0hmZjOCk8s0fOXHT/Chmx8E4PyTjnByMTNL3C02Dcu6O0f2N/fuq2MkZmYzi5PLNCxf4ORiZjYeJ5dp6JnfMbK/ube/jpGYmc0sTi7TsKSrAynb37ann8HicH0DMjObIaqWXCStlbRF0gNjyt8n6SFJD0r6ZK78A5I2SnpY0hm58jNT2UZJl+bKj5T0g1R+g6T2VN6Rjjem8yur9TO2FVpY0pW1XiJg6y63XszMoLotl6uBM/MFkl4JnAMcFxEvAP4mlR8DnAe8IF3zd5IKkgrA54CzgGOA81NdgE8Al0XE84EdwIWp/EJgRyq/LNWrmtFdYx53MTODKiaXiPgusH1M8f8B/joi+lOdLan8HOD6iOiPiF8AG4GT0rYxIh6NiAHgeuAcSQJeBdyUrl8HvD73XuvS/k3Aaal+VfR4xpiZ2bPUeszl14CXpe6q70j6zVR+GPB4rt6mVDZR+SHAMxExNKZ81Hul8ztT/WeRdJGkDZI2bN269aB+oJ5RM8bcLWZmBrVPLq3AYuBk4I+BG6vZqphKRFwZEasjYvXSpc96kFpZ3HIxM3u2WieXTcC/ReaHwDCwBHgCODxXb0Uqm6h8G7BQUuuYcvLXpPMLUv2qyI+5POXkYmYG1D65fAV4JYCkXwPagaeBW4Dz0kyvI4FVwA+BHwGr0sywdrJB/1siIoBvA+em910D3Jz2b0nHpPPfSvWrIt8ttsXdYmZmQBXXFpN0HXAqsETSJuDDwFpgbZqePACsSf/jf1DSjcBPgCHgvRFRTO9zMXAbUADWRsSD6SP+FLhe0l8APwauSuVXAddK2kg2oeC8av2M4G4xM7PxVC25RMT5E5x6ywT1Pw58fJzyW4Fbxyl/lGw22djyfcDvHFCw0+BuMTOzZ/Md+tO0eF47bYVsTsKufUPsHRia4gozs8bn5DJNkkatjuxxFzMzJ5eKcNeYmdloTi4V4KX3zcxGc3KpAHeLmZmN5uRSAT3z9ycXd4uZmTm5VMTyBV4Z2cwsz8mlAnrcLWZmNoqTSwUsc7eYmdkoTi4VMHa2WBWXMjMzmxWcXCqgq6OVee0FAPqHhunt8136ZtbcnFwqxDPGzMz2c3KpkGXzPWPMzKzEyaVCls/3XfpmZiVOLhXS4+RiZjbCyaVClo1KLr7Xxcyam5NLhbhbzMxsPyeXCunxgL6Z2QgnlwrpcbeYmdkIJ5cKyU9F3rq7n+Kw79I3s+bl5FIhHa0FFs1tA6A4HGzb49aLmTUvJ5cKGtU1ttPJxcyal5NLBfleFzOzjJNLBY2aMbbLycXMmpeTSwWN7hZzcjGz5uXkUkGejmxmlnFyqaBRycXdYmbWxJxcKig/5vKUu8XMrIk5uVRQfn2xLbvcLWZmzcvJpYIO6eqgRdn+9j0D9A8V6xuQmVmdOLlUUKFFLO3e3zW2xYP6ZtaknFwqbHTXmMddzKw5VS25SForaYukB3JlH5H0hKR70nZ27twHJG2U9LCkM3LlZ6ayjZIuzZUfKekHqfwGSe2pvCMdb0znV1brZxyPHxpmZlbdlsvVwJnjlF8WEcen7VYASccA5wEvSNf8naSCpALwOeAs4Bjg/FQX4BPpvZ4P7AAuTOUXAjtS+WWpXs14xpiZWRWTS0R8F9heZvVzgOsjoj8ifgFsBE5K28aIeDQiBoDrgXMkCXgVcFO6fh3w+tx7rUv7NwGnpfo1sdz3upiZ1WXM5WJJ96Vus0Wp7DDg8VydTalsovJDgGciYmhM+aj3Sud3pvrPIukiSRskbdi6dev0fzJGd4t5QN/MmlWtk8vngaOA44EngU/X+PNHiYgrI2J1RKxeunRpRd4zf5e+u8XMrFm1TlVB0mrgZcBzgD7gAWB9ROw40A+LiM259/0C8LV0+ARweK7qilTGBOXbgIWSWlPrJF+/9F6bJLUCC1L9mnC3mJnZJC0XSW+XdDfwAWAO8DCwBXgp8E1J6yQdcSAfJunQ3OEbyBIVwC3AeWmm15HAKuCHwI+AVWlmWDvZoP8tERHAt4Fz0/VrgJtz77Um7Z8LfCvVr4n8gL67xcysWU3WcpkLnBIRfeOdlHQ8WRL41QTnrwNOBZZI2gR8GDg1XRfAL4F3AUTEg5JuBH4CDAHvjYhiep+LgduAArA2Ih5MH/GnwPWS/gL4MXBVKr8KuFbSRrIJBedN8R1U1II5bbS3tjAwNMzu/iF29w/R1TFlA9HMrKFoqn/USzolIr43Vdlst3r16tiwYUNF3uvln/w2v9q+F4A7/vAVHLW0qyLva2Y200i6KyJWjy0vZ0D/s2WWWTLqiZR+3LGZNaEJ+2skvRh4CbBU0iW5U/PJuqhsAqPv0ndyMbPmM9lgQDvQlep058p72T+QbuNY7iVgzKzJTZhcIuI7wHckXR0RjwFIagG6IqK3VgHORu4WM7NmV86Yy19Jmi9pHtnU4Z9I+uMqxzWr9bhbzMyaXDnJ5ZjUUnk98HXgSOCtVY1qlutxt5iZNblykkubpDay5HJLRAyS3adiE3DLxcyaXTnJ5R/IbnicB3xX0nPJBvVtAmPv0q/hAgFmZjPClMklIi6PiMMi4uzIPAa8sgaxzVpz21vp7szmSgwUh9mxd7DOEZmZ1daUyUXSAkmfKS1NL+nTZK0Ym4S7xsysmZXTLbYW2AW8KW29wD9VM6hGMOqJlE4uZtZkyllR8aiIeGPu+M8l3VOtgBpFz6iHhjm5mFlzKafl0ifppaUDSaeQPdfFJuHpyGbWzMppubwbuEbSgnS8A3hb1SJqED3d7hYzs+Y1ZXKJiHuB4yTNT8eehlyG5QvcLWZmzWuyJ1FeIunC0nFE9EZEr6QLJb2/NuHNXsvcLWZmTWyyMZc3A9eMU34t8I7qhNM48mMu7hYzs2YzWXJpTUu9jBIRA4CqF1JjWJYbc3l6dz9DxeE6RmNmVluTJZcWST1jC8crs2drK7SwpKsdgAh4evdAnSMyM6udyZLLp4B/l/QKSd1pOxX4GvA3NYlullvW7a4xM2tOkz0s7BpJW4GPAi8kWwn5QeBDEfH1GsU3qy1f0MlPnswm13kJGDNrJpNORU5JxInkII1eHdnJxcyax2RTkf+vpMWTnH+VpNdWJ6zG4G4xM2tWk7Vc7ge+KmkfcDewFegEVgHHA98E/rLqEc5i+Rspfa+LmTWTycZcbgZulrQKOAU4lGxF5H8GLooIry82hXy3mMdczKyZlLP8yyPAIzWIpeHku8W2uOViZk2knFWR7SD5Ln0za1ZOLlV0yLx2WluyxQx29g2yb7BY54jMzGpj0uQiqSDpD2oVTKNpadGoZWDcNWZmzWLS5BIRReD8GsXSkJa5a8zMmlA5Dwv7nqQrgBuAPaXCiLi7alE1kOWjlt53cjGz5lBOcjk+vX40VxbAqyofTuPxdGQza0ZTDuhHxCvH2aZMLJLWStoi6YFxzv2hpJC0JB1L0uWSNkq6T9IJubprJD2StjW58hMl3Z+uuVySUvliSetT/fWSFpX7ZVTDMrdczKwJTZlcJC2Q9BlJG9L2aUkLynjvq4Ezx3m/w4HTgV/lis8iu/N/FXAR8PlUdzHwYeC3gJOAD+eSxeeBd+auK33WpcAdEbEKuCMd181yP5HSzJpQOVOR1wK7gDelrRf4p6kuiojvAtvHOXUZ8CdkXWsl5wDXROZOYKGkQ4EzgPURsT0idgDrgTPTufkRcWdEBNkTM1+fe691aX9drrwuetxyMbMmVM6Yy1ER8cbc8Z9LuudgPkzSOcATEXFv6sUqOQx4PHe8KZVNVr5pnHKAnoh4Mu0/BUz4cDNJF5G1lDjiiCMO9Mcpi8dczKwZldNy6ZP00tKBpFOAA15XTNJc4M+ADx3otQcrtWpikvNXRsTqiFi9dOnSqsTQM2bxyiwkM7PGVk7L5d3ANblxlh3AmknqT+Qo4Eig1GpZAdwt6STgCeDwXN0VqewJ4NQx5f+RyleMUx9gs6RDI+LJ1H225SBirZjujlbmtBXoGyzSN1hkV/8Q8zvb6hmSmVnVTXWHfgtwdEQcBxwLHBsRL4qI+w70gyLi/ohYFhErI2IlWVfWCRHxFHALcEGaNXYysDN1bd0GnC5pURrIPx24LZ3rlXRymiV2AXBz+qhb2J/81uTK60LS6K6xne4aM7PGN9Ud+sNkg+9ERG9E9Jb7xpKuA74PHC1pk6QLJ6l+K/AosBH4AvCe9JnbgY8BP0rbR1MZqc4/pmt+zv4nZv418GpJjwC/nY7rqsczxsysyZTTLfZNSX/Es+/QH28mGLnzky4bk1ovpf0A3jtBvbVkM9bGlm8AXjhO+TbgtMk+u9Y8Y8zMmk05yeV302v+f/4BPK/y4TSmfLeY1xczs2YwaXJJYy5viYjv1SiehpRvuWxxcjGzJlDOmMsVNYqlYXnMxcyaTTn3udwh6Y0ac9ejlc9PpDSzZlNOcnkX8CWgX1KvpF2Syp41ZqPXF3O3mJk1gykH9COiuxaBNLJluQH9Lbv6GR4OWlrcEDSzxjVhy0XSW3L7p4w5d3E1g2o0nW0FFszJ7sofGg627Rmoc0RmZtU1WbfYJbn9z445944qxNLQ/ERKM2smkyUXTbA/3rFNYXTXmJOLmTW2yZJLTLA/3rFNYdSMsZ2ejmxmjW2yAf1fl3QfWSvlqLRPOvbd+QfI3WJm1kwmSy6/UbMomkCPu8XMrIlMmFwi4rFaBtLolo3qFnNyMbPGVs5NlFYBy70EjJk1ESeXGhm1eKW7xcyswTm51MiSrnZKN+U/vXuAgaHh+gZkZlZFE465SLqfSaYcR8SxVYmoQbUWWljS1cGWXVmX2Nbd/Ry2cE6dozIzq47JZou9Nr2WHhJ2bXp9c/XCaWw98ztHksvm3n1OLmbWsKacLSbp1RHxotypSyXdDVxa7eAaTc/8Du5/Itvf7BljZtbAyhlzUX7hSkkvKfM6G6PHN1KaWZOYcsl94EJgraQF6fgZvHDlQRmVXHZ5OrKZNa5ynudyF3BcKblExM6qR9Wg8nfpu1vMzBrZlN1bknokXQVcHxE7JR0j6cIaxNZwRrdcnFzMrHGVM3ZyNXAb8Jx0/DPg/dUKqJH1+C59M2sS5SSXJRFxIzAMEBFDQLGqUTWoUcnF3WJm1sDKSS57JB1CuqFS0smAx10OwqK5bbQXsq98V/8Qe/qH6hyRmVl1lJNcLgFuIXumy/eAa4D3VTWqBiVpzBMp3TVmZo1p0tliklqATuAVwNFkDwp7OCIGaxBbQ+qZ38mmHX1Adq/LkUvm1TkiM7PKmzS5RMSwpM+lO/QfrFFMDc1PpDSzZlBOt9gdkt4oSVWPpgnku8WcXMysUZWTXN4FfAnol9QraZek3irH1bA8HdnMmkE5d+h31yKQZpHvFnvKLRcza1Dl3KH/8vG2Mq5bK2mLpAdyZR+TdJ+keyTdLuk5qVySLpe0MZ0/IXfNGkmPpG1NrvxESfenay4vddtJWixpfaq/XtKiA/1SqmnUbDEnFzNrUOV0i/1xbvt/wFeBj5Rx3dXAmWPKPhURx0bE8cDXgA+l8rOAVWm7CPg8ZIkC+DDwW8BJwIdzyeLzwDtz15U+61LgjohYBdzBDHs0gLvFzKwZTJlcIuJ/5rZXAy8EdpRx3XeB7WPK8mM189j/pMtzgGsicyewUNKhwBnA+ojYHhE7gPXAmenc/Ii4MyKC7N6b1+fea13aX5crnxF6xnSLZeGbmTWWcpbcH2sT8BsH+4GSPg5cQHaX/ytT8WHA42M+47ApyjeNUw7QExFPpv2ngJ5JYrmIrKXEEUcccRA/zYHr6milq6OV3f1DDAwNs7NvkIVz22vy2WZmtVLOmMtn05jG5ZKuAP4TuPtgPzAiPhgRhwNfBC4+2Pcp87OC/a2j8c5fGRGrI2L10qVLqxnKKKOnI7trzMwaTzljLhuAu9L2feBPI+ItFfjsLwJvTPtPAIfnzq1IZZOVrxinHGBz6jYjvW6pQKwV5RljZtboyhlzWZfbvhgR3zvYD5O0Knd4DvBQ2r8FuCDNGjsZ2Jm6tm4DTpe0KA3knw7cls71Sjo5zRK7ALg5916lWWVrcuUzhh93bGaNbsoxl5QQ/go4hmydMQAi4nlTXHcdcCqwRNImsllfZ0s6mmz5/seAd6fqtwJnAxuBvcDb02dsl/Qx4Eep3kcjojRJ4D1kM9LmAF9PG8BfAzemB5o9Brxpqp+x1jwd2cwaXTkD+v9ElhguIxuAfzvltXjOH6f4qgnqBvDeCc6tBdaOU76BbOba2PJtwGlTxVdP7hYzs0ZXzpjLnIi4A1BEPBYRHwFeU92wGpvvdTGzRldOy6U/Lb3/iKSLyQbOu6obVmPrcbeYmTW4clouvw/MBX4POBF4K/sHzO0gLOt2t5iZNbZyFq4sDabvJg202/TkB/S37uqnOBwUWvxEAzNrHOXMFvsqk9+I+LqKRtQEOloLLJ7XzvY9AwwHbNvdz7LcOIyZ2WxXzpjLo8By4J/T8fnAZuAr1QqqGSzr7mD7ngEg6xpzcjGzRlJOcjklIlbnjr8qaUNE/EG1gmoGyxd08tBTuwDPGDOzxlPOgP48SSM3TEo6kmxFY5uGnm7fpW9mjauclssfAP8h6VFAwHNJKwnbwesZtXilk4uZNZZyZot9Iy0B8+up6KGIcD/ONPUscMvFzBrXhN1ikn5T0nKAlEyOAz4KfCo9IdKmYXS3mHO1mTWWycZc/gEYAJD0crIFIa8he8jXldUPrbF5ZWQza2STdYsVcisQ/y5wZUT8K/Cvku6pfmiNrWeBx1zMrHFN1nIpSColn9OAb+XOHczjkS3nkHkdI3fl79g7SP9Qsc4RmZlVzmTJ5TrgO5JuBvrIHm+MpOeTdY3ZNBRaxNKu/AKWHncxs8YxYQskIj4u6Q7gUOD29MwVyBLS+2oRXKPrWdA5snDl5t59HL54bp0jMjOrjEm7tyLiznHKfla9cJpLT3d+3MUtFzNrHOXcoW9V0uMnUppZg3JyqaPluRsp/dAwM2skTi51tKzb05HNrDE5udSRu8XMrFE5udTR6G4xD+ibWeNwcqkjL7tvZo3KyaWO5s9ppaM1+xXsGSiya99gnSMyM6sMJ5c6kjSqa8z3uphZo3ByqbN815inI5tZo3ByqbNluSdSesaYmTUKJ5c6Wz7f3WJm1nicXOosP+byb3dvYnf/UB2jMTOrDCeXOnv1MT20pxljj2zZzSU33MPwcExxlZnZzObkUmfPPWQef/WG/zFyfPtPNvO3dzxSx4jMzKbPyWUGeOOJK/jfLz1y5Phv73iEbzzwZB0jMjObnqolF0lrJW2R9ECu7FOSHpJ0n6QvS1qYO/cBSRslPSzpjFz5malso6RLc+VHSvpBKr9BUnsq70jHG9P5ldX6GSvp0rN+nZetWjJyfMmN9/LQU711jMjM7OBVs+VyNXDmmLL1wAsj4ljgZ8AHACQdA5wHvCBd83eSCpIKwOeAs4BjgPNTXYBPAJdFxPOBHcCFqfxCYEcqvyzVm/FaCy189vwXcUR6GuXegSLvvGYDO/YM1DkyM7MDV7XkEhHfBbaPKbs9IkrToe4EVqT9c4DrI6I/In4BbAROStvGiHg0IgaA64FzJAl4FXBTun4d8Prce61L+zcBp6X6M97Cue3845rVzGsvAPD49j4uvu5uhorDdY7MzOzA1HPM5R3A19P+YcDjuXObUtlE5YcAz+QSVal81Hul8ztT/Vnh13q6+czvHj9y/L2N2/jLWx+qY0RmZgeuLslF0geBIeCL9fj8XBwXSdogacPWrVvrGcooZ7xgOe//7VUjx2u/9wtuumtTHSMyMzswNU8ukt4GvBZ4c0SUbuh4Ajg8V21FKpuofBuwUFLrmPJR75XOL0j1nyUiroyI1RGxeunSpdP8ySrr9161ijNe0DNy/Gdfvp8f/2pHHSMyMytfTZOLpDOBPwFeFxF7c6duAc5LM72OBFYBPwR+BKxKM8PayQb9b0lJ6dvAuen6NcDNufdak/bPBb6VS2KzRkuL+PSbjufonm4ABoaGede1d/m5L2Y2K1RzKvJ1wPeBoyVtknQhcAXQDayXdI+kvweIiAeBG4GfAN8A3hsRxTRmcjFwG/BT4MZUF+BPgUskbSQbU7kqlV8FHJLKLwFGpi/PNl0drXzhgtUsnNsGwJZd/bzr2rvYN1isc2RmZpPTLPxHfVWsXr06NmzYUO8wxvVfjzzNBWt/QGlVmN85cQWfPPdYZskkODNrYJLuiojVY8t9h/4s8NJVS/jga44ZOf7SXZtY99+/rF9AZmZTcHKZJd5xykreeMKKkeOP/ftP+e+NT9cxIjOziTm5zBKS+PgbXshxh2cr5hSHg/f8y908vn3vFFeamdWek8ss0tlW4Mq3nsjS7uzplc/sHeSd12xgj58BY2YzjJPLLNMzv5O/f8uJtBeyX91DT+3ij750L56YYWYziZPLLHTicxfxF2944cjx1x94iiu+tbGOEZmZjebkMku9afXhvO0lK0eOP73+Z9z+4FP1C8jMLKd16io2U33wNb/Bw0/t4vuPZqvbvPuf72LxvHbmz2ljfmcbC+bs3+bPaR1znKszt42u9lZaWnzfjJlVhpPLLNZWaOFzbz6B113xX2za0cdwwNO7B3h694E/A6ZF0N3Zxrz2Au2tLXS0Zq/trS20F1roaMteS2UdrQU6Rvb3n+tobaGrs41Fc9tYOLeNhXPbWTS3nQVz2ig4eZk1DSeXWW7xvHauWvObXHTtBh7bdvDTkocDdvYNsrNvsILRjTa/s5VF89pZOLedhXNKCShLPgtTMirtd3e2Mbe9kLZWJyazWcbLvyQzefmXcu0bLNKbEkTvvsGRZLFz7yA7+4ZGl/UN0pu2nX2D7BmY2euVdba1MK+9lTntBea1tzK3o5A7LjC3ozV7bW/NElLueF5H9trVkZ2bl147Wlu8hI7ZNE20/ItbLg2ks61AZ1uBZfM7D/jaweIwvX2D9A0WGRgaZqA4TP9g9jowNEz/UDG9ZtvA0PDIcVa/SP9gdrxr3yA79g7yzN4BnukbZMeeAXr3Te9enH2Dw+wbHIA903qbUQotypJNLlnlk8+89lY621roaMsSUUepO7Att9/ako4L457vbGuhq6OV1oLnzlhzcXIxIBu/OaSro2rvXxwOdvYNsmPvAM+kxDOSgPam8r79x3v6h9gzUGRv/xB7B4tUo4FdHA527Rti1zQTXznmthfo7mylu7ON7s5W5qfX7s425ne2Mn9O6biV7o620cepi7DNCcpmEScXq4lCi1g8r53F89oP+NqIYN/gMHsGhtjbX8xeB4rsHRhiT396LSWiVL67v0hfqTxfr3R9f5GB4nAVftLxZXEV2dzbf9Dv0VYQc9r2d/3NSWNSc9pbmdtWeHZZab8tK28vtNCWJl+0pQkYbQWNHJfOZfVEW6GF1ha569AOipOLzXiSmJP+x0lX5d53YGiYvoFSskqJp390QuofKmZdgYPD+/eH9ncBjn9+f52+wew9hyvQ8hosBoPFoWl3MR4IKWvVthda6GwrcMi8dg7pyv6RsKSrg8XpOCvPjpfM62D+nNaKJKWIoD/9nvoGs621RSyc0053p6fPz2ROLta0StOqF6SHsVVLRLBnIJtskXXDZa+9+wbpzR/nzufLd+3Lkl8lEtSBx87I+Nru/iGe3t0Pm6e+rjW1VA/p6hiVkDrbCvQNFNmXEkUpaeSP96WkXDo3kRbBgjnZjMMFudmHWdn+mYfZuTQj0UmpZpxczKpMEl0d2Wy1g5X/F/zewazLr9TV1pde9w4M0TdYzJUPjZzvGywyWBxmoBgMDg0zWBweOR4YKqZWUSobGh45HjrIjDY0HGzZ1c+WXQffDTiV4YAde7PJIweiRdlTXud1PHsCx9yOVrrS7MKxsxBLsw7ndWT7XR3ZjcldHZVppTUaJxezWUDSyGzARTX83OLw/qSzp7/Itj39bNs9wPY9Azy9u5/tewbYtnuAbXsG2LZn//HuCq7U3dHaknWLpp9/sDjMzr2D7DrIzxgO6N1Xue7FFjFqxYvSahjzO7OJGdl+Nmlj/3H22tnWMtLt2GitKScXM5tQoUUUWrL/qXd3trF8QXnT3PcNFtm+59lJqH+oyJz21jTJoGUkYZQmHYx97WgtTHgDbWn6/I69g+zsK806zGYc7uwbHJmFOGp/GklpIsNBmgE5vRuQCy2iraCRZNOWm1gxclw637o/KXWl2YdjE9uCuaMT3py2Qk1bWE4uZlZxnW0FnrNwDs9ZOKdqn1GaPn+gU+gHi8O5WYfZzMK9/c+eWbg7zT7ck3vdk5v4sbt/iJ19g+yt0A3IxeGgOJzNjKyGtoJGkk33mBbVgjltvOfUo+jurNz4o5OLmTWVtkILC+ZWbiJHqQXVu29o/8oX+0qrYAyNWjGjVK+0Okb/0P4blattsBip+3L8tQff/YqjKvp5Ti5mZtNwsC2ovIhI41vBQHH/hIvBoWCgWGRgKDfhopgmXKRp77v79yeyfBLbOSbh9U+SwCTonsaEk/E4uZiZ1ZkkWguitQBzKFTlM/YNFrPp77nWVKkF1TdYrPiEAicXM7MmMLL2YGt59vMAAAcSSURBVHdtPs+LFZmZWcU5uZiZWcU5uZiZWcU5uZiZWcU5uZiZWcU5uZiZWcU5uZiZWcUpqvH82FlI0lbgsXrHMYUlwNP1DqIMjrOyZkucMHtidZyV89yIWDq20MllFpG0ISJW1zuOqTjOypotccLsidVxVp+7xczMrOKcXMzMrOKcXGaXK+sdQJkcZ2XNljhh9sTqOKvMYy5mZlZxbrmYmVnFObmYmVnFObnMIJIOl/RtST+R9KCk3x+nzqmSdkq6J20fqkesKZZfSro/xbFhnPOSdLmkjZLuk3RCHWI8Ovdd3SOpV9L7x9Spy3cqaa2kLZIeyJUtlrRe0iPpddEE165JdR6RtKZOsX5K0kPpd/tlSQsnuHbSv5MaxPkRSU/kfr9nT3DtmZIeTn+vl9YhzhtyMf5S0j0TXFuz73NaIsLbDNmAQ4ET0n438DPgmDF1TgW+Vu9YUyy/BJZMcv5s4OuAgJOBH9Q53gLwFNlNX3X/ToGXAycAD+TKPglcmvYvBT4xznWLgUfT66K0v6gOsZ4OtKb9T4wXazl/JzWI8yPAH5Xxt/Fz4HlAO3Dv2P/2qh3nmPOfBj5U7+9zOptbLjNIRDwZEXen/V3AT4HD6hvVtJwDXBOZO4GFkg6tYzynAT+PiBmxEkNEfBfYPqb4HGBd2l8HvH6cS88A1kfE9ojYAawHzqxaoIwfa0TcHhFD6fBOYEU1YyjHBN9pOU4CNkbEoxExAFxP9ruoisnilCTgTcB11fr8WnBymaEkrQReBPxgnNMvlnSvpK9LekFNAxstgNsl3SXponHOHwY8njveRH2T5XlM/B/sTPlOeyLiybT/FNAzTp2Z9r0CvIOslTqeqf5OauHi1H23doKuxpn0nb4M2BwRj0xwfiZ8n1NycpmBJHUB/wq8PyJ6x5y+m6xb5zjgs8BXah1fzksj4gTgLOC9kl5ex1gmJakdeB3wpXFOz6TvdERkfSAz/l4BSR8EhoAvTlCl3n8nnweOAo4HniTrcprJzmfyVku9v8+yOLnMMJLayBLLFyPi38aej4jeiNid9m8F2iQtqXGYpVieSK9bgC+TdS3kPQEcnjtekcrq4Szg7ojYPPbETPpOgc2lrsP0umWcOjPme5X0NuC1wJtTMnyWMv5OqioiNkdEMSKGgS9M8Pkz4juV1Ar8L+CGierU+/ssl5PLDJL6Wq8CfhoRn5mgzvJUD0knkf0Ot9UuypE45knqLu2TDe4+MKbaLcAFadbYycDOXJdPrU34r8GZ8p0mtwCl2V9rgJvHqXMbcLqkRamL5/RUVlOSzgT+BHhdROydoE45fydVNWac7w0TfP6PgFWSjkyt3PPIfhe19tvAQxGxabyTM+H7LFu9ZxR4278BLyXrBrkPuCdtZwPvBt6d6lwMPEg2m+VO4CV1ivV5KYZ7UzwfTOX5WAV8jmwWzv3A6jrFOo8sWSzIldX9OyVLdk8Cg2R9/BcChwB3AI8A3wQWp7qrgX/MXfsOYGPa3l6nWDeSjVOU/lb/PtV9DnDrZH8nNY7z2vT3dx9Zwjh0bJzp+GyyGZo/r0ecqfzq0t9lrm7dvs/pbF7+xczMKs7dYmZmVnFOLmZmVnFOLmZmVnFOLmZmVnFOLmZmVnFOLmbToGwV6zPGlL1f0uenuG53leNaKukHkn4s6WVjzv2HpNVp/8i0svIZ47+T2cFxcjGbnuvIbrjLm2wNs1o5Dbg/Il4UEf85XgVJK4BvAH8YETW/CdMam5OL2fTcBLwm3dVdWnD0OcB/SuqSdIeku9PzN561yq6yZ8l8LXd8RVpSBUknSvpOWqDwtvFWlJa0UtK30qKMd0g6QtLxZEv3n5Oe+TFnnLgPBW4nuwmvHneiW4NzcjGbhojYDvyQbO0yyFotN0Z2d/I+4A2RLTL4SuDTpWVmppLWmPsscG5EnAisBT4+TtXPAusi4liyhSMvj4h7gA8BN0TE8RHRN85164ArIuKmcn9WswPh5GI2ffmusXyXmIC/lHQf2VIuhzH+EvrjORp4IbA+PZHw/zL+81JeDPxL2r+WbAmhcnwTeIukuWXWNzsgrfUOwKwB3AxcpuwxznMj4q5U/mZgKXBiRAxK+iXQOebaIUb/I690XsCDEfHiKsX8SeCtwJcknRP7H/plVhFuuZhNU2TL9X+brOsqP5C/ANiSEssrgeeOc/ljwDGSOpQ9g/60VP4wsFTSiyHrJpvgIWb/zf5W05uBcQfvJ/B+oBe4qtzuOrNyObmYVcZ1wHGMTi5fBFZLuh+4AHho7EUR8ThwI9my6TcCP07lA8C5wCck3Uu26vBLxvnc9wFvT11vbwV+v9yA07jQGrLB/U+We51ZObwqspmZVZxbLmZmVnFOLmZmVnFOLmZmVnFOLmZmVnFOLmZmVnFOLmZmVnFOLmZmVnH/H0XXs60c5fkyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cost =[] \n",
    "# calculatig for 1-20 clusters\n",
    "for i in range(1, 20): \n",
    "    KM = KMeans(n_clusters = i, max_iter = 200) \n",
    "    KM.fit(SBS) \n",
    "    cost.append(KM.inertia_) \n",
    "# Plotting the cost function\n",
    "plt.plot(range(1, 20), cost, linewidth ='3') \n",
    "plt.xlabel(\"Value of K\") \n",
    "plt.ylabel(\"Sqaured Error (Cost)\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P0FpguW2KoeE"
   },
   "source": [
    "The error suddenly drops at 4 (clusters) and is almost constant for any higher number of clusters. So, we will be clustering our data into 5 clusters and the algorithms will be applied over one of the cluster.<br>\n",
    "Generally, to select that one cluster, we pick 5-10% of our data, apply our algorithms over it and see from which cluster max no. of products were selected.<br>\n",
    "By this, we can say that, this cluster consists of good products and runing our algorithm over this would provide best results.<br>\n",
    "But here, our dataset is small and we are doing this only to verify if this technique works. So, we'll just skip the data picking step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nf8kANqXBxZD"
   },
   "outputs": [],
   "source": [
    "n_clusters = 5\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(data[CP])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ykVRAYyoCv5O"
   },
   "outputs": [],
   "source": [
    "# Cluster number of each datapoint\n",
    "labels = list(kmeans.labels_)\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F0kp4b9xHqCY"
   },
   "outputs": [],
   "source": [
    "arr = [[] for i in range(n_clusters)]\n",
    "for i,j in enumerate(labels):\n",
    "\tarr[j].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HYsiJK-LYn9N",
    "outputId": "8b312fea-ad37-4b33-8d3e-e7a70d4ac691"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 385\n",
      "1: 106\n",
      "2: 237\n",
      "3: 233\n",
      "4: 248\n"
     ]
    }
   ],
   "source": [
    "Clusters = [[] for i in range(n_clusters)]\n",
    "for i in range(n_clusters):\n",
    "\tClusters[i] = data[arr[i],:]\n",
    "# Print the no. of products each cluster contains.\n",
    "for i in range(n_clusters):\n",
    "\tprint(\"%d: %d\"% (i,len(Clusters[i])), end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "Cn5qUQlMA2gx",
    "outputId": "318e19af-48d4-421a-e360-8f9983e3c210"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "products selected by SPG algo\n",
      "[1, 1, 1, 1, 1]\n",
      "\n",
      "products selected by IG algo\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "selected_products = []\n",
    "print(\"\\nproducts selected by SPG algo\")\n",
    "for i in SPG_k:\n",
    "\tselected_products.append(labels[i[1]])\n",
    "print(selected_products)\n",
    "print(\"\\nproducts selected by IG algo\")\n",
    "for i in IG_k:\n",
    "\tselected_products.append(labels[i])\n",
    "print(selected_products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sXuIUb_mTpSD"
   },
   "source": [
    "In the above case, majority of the products were selected from 4th cluster.<br>\n",
    "So, we will run the algorithms once again over 4th cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "GYyENrTXEClN",
    "outputId": "c97d114d-1564-4731-a20b-dc6c9bb3042e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Single Product Based Greedy Algorithm : \n",
      " [(2.247524752475249, 49), (2.267326732673269, 25), (2.252475247524754, 103), (2.2821782178217838, 42), (2.277227722772279, 87)]\n",
      "Time taken: 1\n",
      "Incremental Based Greedy Algorithm : \n",
      " [ 42  87  25 103  32]\n",
      "Time taken: 4\n"
     ]
    }
   ],
   "source": [
    "# Run over the cluster from which majority of the products have been selected previously.\n",
    "cluster = max(set(selected_products), key = selected_products.count)\n",
    "print(cluster)\n",
    "\n",
    "SBS_New = SBS[arr[cluster]]\n",
    "SBS_New = np.append(SBS_New, SBS[EP,:], axis=0)\n",
    "h,w = SBS_New.shape\n",
    "\n",
    "# Creating Sets of Customers, Candidate Products and Existing Products.\n",
    "C = np.arange(0, w)\n",
    "# CP = np.arange(0, (h*70)//100)\n",
    "# EP = np.arange((h*70)//100, h)\n",
    "CP = np.arange(0, len(Clusters[cluster]))\n",
    "EP = np.arange(len(Clusters[cluster]), h)\n",
    "\n",
    "\n",
    "# SPGA\n",
    "timeTaken = datetime.datetime.now()\n",
    "CSPG_k = SPG(k, SBS_New, EP, CP)\n",
    "timeTaken = datetime.datetime.now() - timeTaken \n",
    "print(\"Single Product Based Greedy Algorithm : \\n\", CSPG_k)\n",
    "print(\"Time taken:\", timeTaken.seconds)\n",
    "\n",
    "# IG\n",
    "timeTaken = datetime.datetime.now()\n",
    "CIG_k = IG(k, SBS_New, EP, CP)\n",
    "timeTaken = datetime.datetime.now() - timeTaken\n",
    "print(\"Incremental Based Greedy Algorithm : \\n\", CIG_k)\n",
    "print(\"Time taken:\", timeTaken.seconds)\n",
    "\n",
    "# # UBP\n",
    "# timeTaken = datetime.datetime.now()\n",
    "# CUBP_k = UBP(k, SBS_New, EP, CP)\n",
    "# timeTaken = datetime.datetime.now() - timeTaken\n",
    "# print(\"Upper Bound Pruning Algorithm : \\n\", CUBP_k)\n",
    "# print(\"Time taken:\", timeTaken.seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "YkL1iu_maslj",
    "outputId": "0a42b2e0-3486-4658-8b39-b6b2b0b76c71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "products selected by CSPG algo\n",
      "601, 378, 1195, 540, 1051, \n",
      "products selected by CIG algo\n",
      "540, 1051, 378, 1195, 457, "
     ]
    }
   ],
   "source": [
    "print(\"\\nproducts selected by CSPG algo\")\n",
    "for i in CSPG_k:\n",
    "\tprint(arr[cluster][i[1]], end=', ')\n",
    "print(\"\\nproducts selected by CIG algo\")\n",
    "for i in CIG_k:\n",
    "\tprint(arr[cluster][i], end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-18-aa5af5d4054b>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-aa5af5d4054b>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Single Product Based Greedy Algorithm :\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Single Product Based Greedy Algorithm : \n",
    " [(1.031818181818188, 601), (1.0409090909090968, 378), (1.0340909090909152, 1195), (1.0454545454545512, 1051), (1.0477272727272784, 540)]\n",
    "Time taken: 4\n",
    "Incremental Based Greedy Algorithm : \n",
    " [ 540 1051  378 1195  457]\n",
    "Time taken: 36\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Single Product Based Greedy Algorithm : \n",
    " [(1.031818181818188, 601), (1.0409090909090968, 378), (1.0340909090909152, 1195), (1.0454545454545512, 1051), (1.0477272727272784, 540)]\n",
    "Time taken: 4\n",
    "Incremental Based Greedy Algorithm : \n",
    " [ 540 1051  378 1195  457]\n",
    "Time taken: 36"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EjeaQY1oVph2"
   },
   "source": [
    "# Conclusion\n",
    "<b> Running over the whole data set</b> <br>\n",
    "Single Product Based Greedy Algorithm : <br>\n",
    " [(0.995594713656393, 927), (0.9977973568281991, 601), (0.995594713656393, 1144), (1.0022026431718114, 830), (1.0088105726872296, 1119)]<br>\n",
    "Time taken: 3 <br>\n",
    "Incremental Based Greedy Algorithm : <br>\n",
    " [1119  830  601  927 1144] <br>\n",
    "Time taken: 27 <br><br>\n",
    "\n",
    "<b> Running over cluster 4</b> <br>\n",
    "products selected by CSPG algo <br>\n",
    "927, 601, 1144, 830, 1119,  <br>\n",
    "Time taken: 0 <br>\n",
    "products selected by CIG algo <br>\n",
    "1119, 830, 601, 927, 1144,  <br>\n",
    "Time taken: 2 <br>\n",
    "<br>\n",
    "As we can see, the results were the same in both cases and the time taken is very low when we apply over only one cluster.<br>\n",
    "Thus KMDP can be optimised up to **10x** using K-means technique.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "colab": {
   "collapsed_sections": [
    "0Lf407M54epu",
    "JNlJmU8Z4ep-",
    "r9WBiwHy4eqR",
    "md0nksdR4eqf"
   ],
   "name": "k-MostDemandingProducts.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
